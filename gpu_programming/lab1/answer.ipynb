{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1_analysis"
      },
      "source": [
        "## 1. Analyse de la structure du code\n",
        "\n",
        "**a) Étapes principales et gestion de la mémoire**\n",
        "\n",
        "- **Allocation et initialisation** : Le programme alloue la mémoire sur le CPU pour les matrices A, B et C, et initialise A et B avec des valeurs aléatoires.\n",
        "- **Création du contexte cuBLAS** : Un handle (`cublasHandle_t`) est créé avec `cublasCreate` pour gérer l'état de la bibliothèque cuBLAS.\n",
        "- **Allocation GPU et transfert** : La mémoire est allouée sur le GPU pour les copies de A, B et C à l'aide de `cudaMalloc`. Les données de A et B sont transférées du CPU vers le GPU via `cudaMemcpy`.\n",
        "- **Calcul sur GPU** : La multiplication matricielle est effectuée sur le GPU en appelant `cublasSgemm`.\n",
        "- **Retour des résultats** : La matrice résultat C est copiée du GPU vers le CPU.\n",
        "- **Libération des ressources** : Les mémoires allouées sur le GPU et le CPU sont libérées, et le handle cuBLAS est détruit avec `cublasDestroy`.\n",
        "\n",
        "La gestion explicite de la mémoire entre le CPU et le GPU est nécessaire car ces deux entités disposent de mémoires physiques séparées. Les données doivent être transférées explicitement pour être accessibles par le GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1_handle"
      },
      "source": [
        "**b) Rôle du `cublasHandle_t`**\n",
        "\n",
        "Le `cublasHandle_t` est un objet qui représente le contexte d'exécution de la bibliothèque cuBLAS. Il permet de conserver l'état et les configurations nécessaires pour exécuter les fonctions de la bibliothèque. `cublasCreate` initialise ce contexte et alloue les ressources nécessaires, tandis que `cublasDestroy` libère ces ressources une fois les opérations terminées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1_transposition"
      },
      "source": [
        "**c) Signification des paramètres `CUBLAS_OP_N`**\n",
        "\n",
        "Les paramètres `CUBLAS_OP_N` indiquent que les matrices ne doivent pas être transposées lors de l'appel à `cublasSgemm`. Si l’un d’eux était remplacé par `CUBLAS_OP_T`, la matrice correspondante serait transposée avant la multiplication, ce qui modifierait l'ordre des éléments et pourrait changer les dimensions ou les valeurs du résultat final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1_storage_order"
      },
      "source": [
        "**d) Impact de l’ordre de stockage (row-major vs column-major)**\n",
        "\n",
        "CuBLAS utilise par défaut le format column-major (comme en Fortran), alors que le C standard emploie souvent le format row-major. Ce décalage peut entraîner des interprétations erronées des matrices lors du calcul. Il faut alors soit adapter les paramètres de la fonction (par exemple, en transposant les matrices logiquement), soit convertir explicitement les données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2_comparison"
      },
      "source": [
        "## 2. Comparaison cuBLAS vs calcul natif\n",
        "\n",
        "**a) Implémentation native vs cuBLAS**\n",
        "\n",
        "Voir parti Code\n",
        "\n",
        "**b) Mesure du temps d’exécution et comparaison des performances**\n",
        "Voir parti Code\n",
        "\n",
        "\n",
        "**c) Difficultés d'une version parallèle native sur GPU**\n",
        "\n",
        "Écrire une version native en CUDA impliquerait de gérer manuellement :\n",
        "- L'organisation des threads et des blocs pour assurer une utilisation efficace des cœurs GPU.\n",
        "- La gestion de la mémoire partagée pour optimiser les accès aux données.\n",
        "- La synchronisation entre threads et la minimisation des accès non coalescés.\n",
        "\n",
        "Ces aspects sont abstraits par cuBLAS, qui offre une implémentation hautement optimisée sans que l'utilisateur ait à gérer ces détails complexes.\n",
        "\n",
        "**d) Pertinence de cuBLAS pour de petites matrices**\n",
        "\n",
        "Pour des matrices de petite taille (ex. N = 16), les surcharges liées au lancement de kernels et aux transferts de données entre le CPU et le GPU peuvent être significatives, au point que l'avantage de l'accélération par GPU est perdu. Dans ce cas, une implémentation native sur CPU peut être plus efficace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing large_matrix_mul.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile large_matrix_mul.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "// Utility function declarations\n",
        "void initializeMatrix(float *matrix, int rows, int cols);\n",
        "void printMatrixSubset(float *matrix, int rows, int cols, const char *name);\n",
        "void cpuMatrixMultiply(float *A, float *B, float *C, int m, int n, int k);\n",
        "void compareResults(float *cpuResult, float *gpuResult, int size);\n",
        "\n",
        "int main() {\n",
        "    // Matrix dimensions\n",
        "    int N = 1024;\n",
        "    \n",
        "    // Allocate host memory\n",
        "    float *h_A = (float*)malloc(N * N * sizeof(float));\n",
        "    float *h_B = (float*)malloc(N * N * sizeof(float));\n",
        "    float *h_C_cpu = (float*)malloc(N * N * sizeof(float));\n",
        "    float *h_C_gpu = (float*)malloc(N * N * sizeof(float));\n",
        "    \n",
        "    if (!h_A || !h_B || !h_C_cpu || !h_C_gpu) {\n",
        "        fprintf(stderr, \"Host memory allocation failed\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    \n",
        "    // Initialize matrices\n",
        "    printf(\"Initializing matrices...\\n\");\n",
        "    initializeMatrix(h_A, N, N);\n",
        "    initializeMatrix(h_B, N, N);\n",
        "    \n",
        "    // Print small subsets to verify data\n",
        "    printMatrixSubset(h_A, N, N, \"Matrix A (subset)\");\n",
        "    printMatrixSubset(h_B, N, N, \"Matrix B (subset)\");\n",
        "    \n",
        "    // ---------------- CPU Matrix Multiplication ----------------\n",
        "    printf(\"Performing CPU matrix multiplication...\\n\");\n",
        "    \n",
        "    clock_t cpu_start = clock();\n",
        "    cpuMatrixMultiply(h_A, h_B, h_C_cpu, N, N, N);\n",
        "    clock_t cpu_end = clock();\n",
        "    \n",
        "    double cpu_time = ((double)(cpu_end - cpu_start)) / CLOCKS_PER_SEC;\n",
        "    printf(\"CPU matrix multiplication completed in %.3f seconds\\n\", cpu_time);\n",
        "    \n",
        "    // ---------------- cuBLAS Matrix Multiplication ----------------\n",
        "    printf(\"Performing GPU matrix multiplication with cuBLAS...\\n\");\n",
        "    \n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_B, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_C, N * N * sizeof(float));\n",
        "    \n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    // Create cuBLAS handle\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "    \n",
        "    // Copy matrices from host to device\n",
        "    cudaMemcpy(d_A, h_A, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // Perform matrix multiplication using cuBLAS\n",
        "    float alpha = 1.0f;\n",
        "    float beta = 0.0f;\n",
        "    \n",
        "    cudaEventRecord(start);\n",
        "    \n",
        "    // Note: cuBLAS uses column-major order, so we compute B * A instead of A * B\n",
        "    // C = alpha*op(A)*op(B) + beta*C\n",
        "    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, \n",
        "                N, N, N, \n",
        "                &alpha, \n",
        "                d_B, N,  // Matrix B\n",
        "                d_A, N,  // Matrix A\n",
        "                &beta, \n",
        "                d_C, N); // Matrix C result\n",
        "    \n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    \n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(h_C_gpu, d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // Calculate elapsed time\n",
        "    float gpu_time = 0;\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "    printf(\"GPU matrix multiplication completed in %.3f seconds\\n\", gpu_time/1000.0);\n",
        "    \n",
        "    // Compare results\n",
        "    printMatrixSubset(h_C_cpu, N, N, \"CPU Result (subset)\");\n",
        "    printMatrixSubset(h_C_gpu, N, N, \"GPU Result (subset)\");\n",
        "    compareResults(h_C_cpu, h_C_gpu, N * N);\n",
        "    \n",
        "    // Print performance comparison\n",
        "    printf(\"\\nPerformance Comparison:\\n\");\n",
        "    printf(\"CPU time: %.3f seconds\\n\", cpu_time);\n",
        "    printf(\"GPU time: %.3f seconds\\n\", gpu_time/1000.0);\n",
        "    printf(\"Speedup: %.2fx\\n\", cpu_time/(gpu_time/1000.0));\n",
        "    \n",
        "    // Calculate GFLOPS (Giga Floating Point Operations Per Second)\n",
        "    double cpu_gflops = (2.0 * N * N * N) / (cpu_time * 1e9);\n",
        "    double gpu_gflops = (2.0 * N * N * N) / ((gpu_time/1000.0) * 1e9);\n",
        "    printf(\"CPU Performance: %.2f GFLOPS\\n\", cpu_gflops);\n",
        "    printf(\"GPU Performance: %.2f GFLOPS\\n\", gpu_gflops);\n",
        "    \n",
        "    // Cleanup\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C_cpu);\n",
        "    free(h_C_gpu);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    cublasDestroy(handle);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    \n",
        "    printf(\"\\n--- Complexity Analysis ---\\n\");\n",
        "    printf(\"Native CPU Implementation: O(N³) complexity\\n\");\n",
        "    printf(\"- Triple-nested loops iterating through all matrix elements\\n\");\n",
        "    printf(\"- No optimization for cache locality or parallelism\\n\\n\");\n",
        "    \n",
        "    printf(\"cuBLAS Implementation: Effectively O(N³) but highly optimized\\n\");\n",
        "    printf(\"- Uses tiling to maximize cache utilization\\n\");\n",
        "    printf(\"- Employs thousands of parallel threads on GPU\\n\");\n",
        "    printf(\"- Utilizes specialized matrix multiplication hardware (Tensor Cores if available)\\n\");\n",
        "    printf(\"- Implements advanced blocking strategies to minimize memory access latency\\n\");\n",
        "    printf(\"- Benefits from decades of research in optimizing matrix operations\\n\");\n",
        "    \n",
        "    return 0;\n",
        "}\n",
        "\n",
        "// Initialize matrix with random values\n",
        "void initializeMatrix(float *matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            matrix[i * cols + j] = (float)(rand() % 100) / 100.0f;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Print a small subset of the matrix to verify data\n",
        "void printMatrixSubset(float *matrix, int rows, int cols, const char *name) {\n",
        "    printf(\"%s (3x3 corner):\\n\", name);\n",
        "    int display_size = 3;\n",
        "    for (int i = 0; i < display_size && i < rows; i++) {\n",
        "        for (int j = 0; j < display_size && j < cols; j++) {\n",
        "            printf(\"%.4f \", matrix[i * cols + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "// Native CPU matrix multiplication implementation\n",
        "void cpuMatrixMultiply(float *A, float *B, float *C, int m, int n, int k) {\n",
        "    // A: m x k matrix\n",
        "    // B: k x n matrix\n",
        "    // C: m x n matrix (result)\n",
        "    \n",
        "    // Classic triple loop matrix multiplication\n",
        "    for (int i = 0; i < m; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            float sum = 0.0f;\n",
        "            for (int p = 0; p < k; p++) {\n",
        "                sum += A[i * k + p] * B[p * n + j];\n",
        "            }\n",
        "            C[i * n + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Compare CPU and GPU results for accuracy\n",
        "void compareResults(float *cpuResult, float *gpuResult, int size) {\n",
        "    float epsilon = 1e-3;  // Tolerance for floating point comparison\n",
        "    int errors = 0;\n",
        "    \n",
        "    for (int i = 0; i < size; i++) {\n",
        "        if (fabs(cpuResult[i] - gpuResult[i]) > epsilon) {\n",
        "            errors++;\n",
        "            if (errors < 10) {\n",
        "                printf(\"Error at index %d: CPU = %f, GPU = %f\\n\", \n",
        "                      i, cpuResult[i], gpuResult[i]);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    if (errors > 0) {\n",
        "        printf(\"Found %d errors (tolerance: %e)\\n\", errors, epsilon);\n",
        "    } else {\n",
        "        printf(\"Results match! No errors found.\\n\");\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o matrix_multiply matrix_multiply.cu -lcublas\n",
        "! ./matrix_multiply\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3_memory"
      },
      "source": [
        "## 3. Gestion de la mémoire\n",
        "\n",
        "**a) Rôle de `cudaMalloc` et `cudaMemcpy`**\n",
        "\n",
        "Les fonctions `cudaMalloc` et `cudaMemcpy` sont utilisées pour allouer et transférer explicitement les données dans l'espace mémoire du GPU, qui est distinct de celui du CPU. Si on omettait l'appel à `cudaMemcpy` avant `cublasSgemm`, le GPU ne disposerait pas des données initialisées sur le CPU, ce qui conduirait à des erreurs ou à des résultats incorrects.\n",
        "\n",
        "**b) Calcul de la mémoire GPU allouée pour N = 1024**\n",
        "\n",
        "Pour chaque matrice :\n",
        "- Taille = 1024 x 1024 x 4 bytes (pour un float) ≈ 4 Mo.\n",
        "\n",
        "Pour 3 matrices (A, B, C) : environ 12 Mo au total.\n",
        "\n",
        "Si N doublait (N = 2048), la mémoire par matrice serait proportionnelle à N², donc environ 4 fois plus élevée, soit environ 48 Mo pour les trois matrices.\n",
        "\n",
        "**c) Risques en oubliant `cudaFree`**\n",
        "\n",
        "Omettre d'appeler `cudaFree` pour libérer `d_A`, `d_B` et `d_C` provoquerait une fuite de mémoire sur le GPU, réduisant ainsi la mémoire disponible pour d'autres calculs. On peut vérifier la libération de la mémoire en utilisant des outils comme `nvidia-smi`, qui affichent l'utilisation de la mémoire GPU.\n",
        "\n",
        "**d) Différence entre `cudaMallocManaged` et `cudaMalloc`**\n",
        "\n",
        "`cudaMallocManaged` alloue une mémoire unifiée accessible à la fois par le CPU et le GPU, simplifiant ainsi le transfert de données. En revanche, `cudaMalloc` réserve de la mémoire exclusivement sur le GPU, nécessitant des transferts explicites via `cudaMemcpy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4_parameters"
      },
      "source": [
        "## 4. Paramètres de cuBLAS\n",
        "\n",
        "**a) Rôle des paramètres `alpha` et `beta`**\n",
        "\n",
        "Dans l'appel à `cublasSgemm`, le calcul réalisé est :\n",
        "\n",
        "    C = alpha * A * B + beta * C\n",
        "\n",
        "Les paramètres `alpha` et `beta` permettent de scaler respectivement le produit matriciel et la matrice C déjà existante. Si `beta` était fixé à 1.0f sans initialiser C, les valeurs non définies de C seraient ajoutées au résultat, entraînant des erreurs.\n",
        "\n",
        "**b) Modification pour calculer C = 2A * B + 3C**\n",
        "\n",
        "Il suffit de remplacer `alpha` par 2.0f et `beta` par 3.0f dans l'appel à `cublasSgemm`.\n",
        "\n",
        "**c) Adaptation pour des matrices non carrées**\n",
        "\n",
        "Pour multiplier, par exemple, une matrice A de taille 512x1024 par une matrice B de taille 1024x768, il faut adapter les dimensions dans l'appel à `cublasSgemm` :\n",
        "- m = 512 (nombre de lignes de A),\n",
        "- n = 768 (nombre de colonnes de B),\n",
        "- k = 1024 (nombre de colonnes de A ou lignes de B).\n",
        "\n",
        "Les paramètres de stride et les leading dimensions doivent également être ajustés en conséquence.\n",
        "\n",
        "**d) Fonctions batched dans cuBLAS**\n",
        "\n",
        "CuBLAS propose des fonctions pour la multiplication de matrices en mode batched, telles que `cublasSgemmBatched` et `cublasSgemmStridedBatched`, permettant d'exécuter plusieurs multiplications en parallèle en passant des tableaux de pointeurs vers les matrices ou en utilisant un stride constant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5_optimization"
      },
      "source": [
        "## 5. Optimisation et performance\n",
        "\n",
        "**a) Pourquoi cuBLAS est-il plus rapide pour N = 1024 ?**\n",
        "\n",
        "CuBLAS exploite le parallélisme massif des GPU, utilisant des milliers de cœurs et des optimisations spécifiques (comme la gestion efficace des accès mémoire et l'utilisation de Tensor Cores sur certaines architectures) pour accélérer les calculs de grande envergure.\n",
        "\n",
        "**b) Avantage de cuBLAS pour de petites matrices (ex. N = 16)**\n",
        "\n",
        "Pour des matrices de très petite taille, l'overhead associé aux lancements de kernels et aux transferts de données entre CPU et GPU peut surpasser les bénéfices du calcul parallèle. Ainsi, pour N = 16, une implémentation CPU native pourrait être plus performante en raison de la faible charge de calcul et de l'absence d'overhead de transfert.\n",
        "\n",
        "**c) Traitement de matrices trop grandes pour la mémoire GPU**\n",
        "\n",
        "Pour des matrices trop grandes (par exemple, N = 10000), il est pertinent de découper le problème en sous-blocs (technique de tiling). Chaque bloc est multiplié séparément sur le GPU et les résultats sont ensuite assemblés pour former la matrice finale. Cette approche permet de traiter des matrices dont la taille excède la mémoire disponible sur le GPU.\n",
        "\n",
        "**d) Impact du choix des blocs et des threads dans un kernel CUDA personnalisé**\n",
        "\n",
        "Le choix de la taille des blocs et du nombre de threads influe directement sur l'efficacité de l'utilisation des ressources GPU, la coalescence des accès mémoire et l'utilisation de la mémoire partagée. Une mauvaise configuration peut entraîner une sous-utilisation des capacités du GPU et une dégradation significative des performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6_extensions"
      },
      "source": [
        "## 6. Extensions et réflexion\n",
        "\n",
        "**a) Passage en double précision**\n",
        "\n",
        "Pour utiliser des nombres en double précision, il faut :\n",
        "- Remplacer le type `float` par `double` dans la déclaration des matrices.\n",
        "- Utiliser `cublasDgemm` au lieu de `cublasSgemm`.\n",
        "- Adapter les constantes `alpha` et `beta` (par exemple, 1.0f deviendra 1.0 en double).\n",
        "\n",
        "**b) Optimisation pour des multiplications consécutives**\n",
        "\n",
        "Si plusieurs multiplications doivent être réalisées (par exemple, C = A * B suivi de D = C * E), il est avantageux de conserver les matrices intermédiaires dans la mémoire GPU afin de minimiser les transferts entre le CPU et le GPU.\n",
        "\n",
        "**c) Utilisation de plusieurs GPU**\n",
        "\n",
        "Pour exploiter plusieurs GPU, il est nécessaire de partitionner les matrices et de distribuer les calculs entre les différents dispositifs. Les principaux défis incluent la synchronisation inter-GPU, la gestion des transferts de données entre GPU, et la répartition équilibrée de la charge de travail.\n",
        "\n",
        "**d) Optimisations sur les architectures récentes**\n",
        "\n",
        "CuBLAS intègre des optimisations pour les architectures récentes comme Ampere ou Hopper, notamment via l'utilisation des Tensor Cores et des fonctionnalités avancées offertes par cuBLASLt, qui permettent un contrôle plus fin et des performances accrues pour certaines opérations de multiplication matricielle."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
